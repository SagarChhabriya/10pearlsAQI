name: Training Pipeline - Daily

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual triggering

jobs:
  run-training-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: read
      issues: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Check disk space
        run: |
          df -h
          echo "Available disk space before installation"
      
      - name: Verify workflow version
        run: |
          echo "=== WORKFLOW VERSION CHECK ==="
          echo "If you see this message, the updated workflow is running"
          echo "This workflow does NOT use requirements.txt"
          if [ -f requirements.txt ]; then
            echo "WARNING: requirements.txt exists but should NOT be used"
          fi
      
      - name: Install dependencies
        env:
          # Prevent CUDA dependencies from being installed
          XGBOOST_BUILD_TYPE: cpu
          CUDA_VISIBLE_DEVICES: ""
        run: |
          # ====================================================================
          # IMPORTANT: This workflow does NOT use requirements.txt
          # requirements.txt contains heavy packages (TensorFlow, PyTorch, etc.)
          # that cause "No space left on device" errors in GitHub Actions
          # ====================================================================
          
          # Delete requirements.txt to prevent ANY accidental usage
          if [ -f requirements.txt ]; then
            rm requirements.txt
            echo "DELETED requirements.txt to prevent usage"
          fi
          
          # Also prevent setup.py from installing dependencies
          if [ -f setup.py ]; then
            mv setup.py setup.py.backup
            echo "Temporarily disabled setup.py"
          fi
          
          python -m pip install --upgrade pip
          # Clean pip cache to save space
          pip cache purge || true
          
          # Set TMPDIR to home directory (more space available)
          mkdir -p $HOME/tmp
          export TMPDIR=$HOME/tmp
          export PIP_TEMP_DIR=$HOME/tmp
          
          # Free up disk space by removing unnecessary packages if they exist
          pip uninstall -y tensorflow torch gradio streamlit apache-airflow shap lime matplotlib seaborn plotly fastapi uvicorn || true
          
          # Install ONLY essential packages (one at a time to save space and catch errors early)
          echo "=== Installing core dependencies (NOT from requirements.txt) ==="
          pip install --no-cache-dir --no-build-isolation pandas>=2.0.0 numpy>=1.24.0 python-dotenv>=1.0.0 pyyaml>=6.0 requests>=2.31.0
          
          echo "=== Installing database drivers ==="
          pip install --no-cache-dir --no-build-isolation pymongo>=4.6.0 motor>=3.3.0
          
          echo "=== Installing scikit-learn ==="
          pip install --no-cache-dir --no-build-isolation scikit-learn>=1.3.0
          
          echo "=== Installing XGBoost 1.7.x (CPU-only, no CUDA) ==="
          pip install --no-cache-dir --no-build-isolation "xgboost>=1.7.0,<2.0.0"
          
          echo "=== Installing LightGBM (CPU-only) ==="
          pip install --no-cache-dir --no-build-isolation lightgbm>=4.0.0
          
          # Restore setup.py (but NOT requirements.txt - it stays deleted)
          if [ -f setup.py.backup ]; then
            mv setup.py.backup setup.py
          fi
          
          # Verify what was installed and check for unwanted packages
          echo "=== Verifying installation ==="
          pip list | head -30
          echo "=== Checking for unwanted packages ==="
          pip list | grep -E "(tensorflow|torch|gradio|streamlit|airflow|shap|lime)" && echo "ERROR: Unwanted packages found!" || echo "âœ“ No unwanted packages"
      
      - name: Check disk space after installation
        run: |
          df -h
          echo "Available disk space after installation"
      
      - name: Create directories
        run: |
          mkdir -p models logs
      
      - name: Run training pipeline
        env:
          MONGODB_URI: ${{ secrets.MONGODB_URI }}
        run: |
          python pipelines/training_pipeline.py
      
      - name: Upload model artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trained-models
          path: |
            models/**/*.pkl
            models/**/*.json
            logs/*.log
          retention-days: 30
      
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            try {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `Training Pipeline Failed - ${new Date().toISOString()}`,
                body: `The daily training pipeline failed. Check the workflow run for details: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
              });
              console.log('Issue created successfully');
            } catch (error) {
              console.log(`Failed to create issue: ${error.message}`);
              console.log(`Workflow failed. Check run: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`);
            }