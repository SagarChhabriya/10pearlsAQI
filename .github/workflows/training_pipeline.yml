name: Training Pipeline - Daily

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual triggering

jobs:
  run-training-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: read
      issues: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Check disk space
        run: |
          df -h
          echo "Available disk space before installation"
      
      - name: Install dependencies
        env:
          # Prevent CUDA dependencies from being installed
          XGBOOST_BUILD_TYPE: cpu
          CUDA_VISIBLE_DEVICES: ""
        run: |
          # IMPORTANT: Do NOT use requirements.txt - it contains heavy packages that cause disk space issues
          # We install only the minimal dependencies needed for training pipeline
          
          python -m pip install --upgrade pip
          # Clean pip cache to save space
          pip cache purge || true
          
          # Free up disk space by removing unnecessary packages if they exist
          pip uninstall -y tensorflow torch gradio streamlit apache-airflow shap lime matplotlib seaborn plotly fastapi uvicorn || true
          
          # Install ONLY essential packages (one at a time to save space and catch errors early)
          echo "Installing core dependencies..."
          pip install --no-cache-dir pandas>=2.0.0 numpy>=1.24.0 python-dotenv>=1.0.0 pyyaml>=6.0 requests>=2.31.0
          
          echo "Installing database drivers..."
          pip install --no-cache-dir pymongo>=4.6.0 motor>=3.3.0
          
          echo "Installing scikit-learn..."
          pip install --no-cache-dir scikit-learn>=1.3.0
          
          echo "Installing XGBoost 1.7.x (CPU-only, no CUDA)..."
          pip install --no-cache-dir "xgboost>=1.7.0,<2.0.0"
          
          echo "Installing LightGBM (CPU-only)..."
          pip install --no-cache-dir lightgbm>=4.0.0
          
          # Verify what was installed and check for unwanted packages
          echo "Verifying installation..."
          pip list | head -30
          echo "Checking for unwanted packages..."
          pip list | grep -E "(tensorflow|torch|gradio|streamlit|airflow|shap|lime)" && echo "WARNING: Unwanted packages found!" || echo "âœ“ No unwanted packages found"
      
      - name: Check disk space after installation
        run: |
          df -h
          echo "Available disk space after installation"
      
      - name: Create directories
        run: |
          mkdir -p models logs
      
      - name: Run training pipeline
        env:
          MONGODB_URI: ${{ secrets.MONGODB_URI }}
        run: |
          python pipelines/training_pipeline.py
      
      - name: Upload model artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trained-models
          path: |
            models/**/*.pkl
            models/**/*.json
            logs/*.log
          retention-days: 30
      
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            try {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `Training Pipeline Failed - ${new Date().toISOString()}`,
                body: `The daily training pipeline failed. Check the workflow run for details: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`
              });
              console.log('Issue created successfully');
            } catch (error) {
              console.log(`Failed to create issue: ${error.message}`);
              console.log(`Workflow failed. Check run: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`);
            }